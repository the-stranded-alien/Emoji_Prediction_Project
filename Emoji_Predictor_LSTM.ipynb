{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emoji Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1. Get The Emoji Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(emoji.EMOJI_UNICODE)\n",
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":grinning_face_with_big_eyes:\",\n",
    "                    \"3\": \":disappointed_face:\",\n",
    "                    \"4\": \":fork_and_knife:\"\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ù§Ô∏è\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòû\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "for e in emoji_dictionary.values():\n",
    "    print(emoji.emojize(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-2. Processing A Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Dataset/train_emoji.csv\", header=None)\n",
    "test = pd.read_csv(\"Dataset/test_emoji.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>never talk to me again</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I am proud of your achievements</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It is the worst day in my life</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss you so much</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food is life</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0  1   2     3\n",
       "0           never talk to me again  3 NaN   NaN\n",
       "1  I am proud of your achievements  2 NaN   NaN\n",
       "2   It is the worst day in my life  3 NaN   NaN\n",
       "3                 Miss you so much  0 NaN   [0]\n",
       "4                     food is life  4 NaN   NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 4)\n"
     ]
    }
   ],
   "source": [
    "data = train.values\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[0]\n",
    "Y_train = train[1]\n",
    "\n",
    "X_test = test[0]\n",
    "Y_test = test[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing The Sentences With Emojis !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÉ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(X_train[i], emoji.emojize(emoji_dictionary[str(Y_train[i])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-3. Converting Sentences Into Embeddings Using Glove Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"glove.6B.50d.txt\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float')\n",
    "    embeddings_index[word] = coefs\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.4295e-01 -4.2946e-01 -5.4277e-01 -1.0307e+00  1.2056e+00 -2.7174e-01\n",
      " -6.3561e-01 -1.5065e-02  3.7856e-01  4.6474e-02 -1.3102e-01  6.0500e-01\n",
      "  1.6391e+00  2.3940e-01  1.2128e+00  8.3178e-01  7.3893e-01  1.5200e-01\n",
      " -1.4175e-01 -8.8384e-01  2.0829e-02 -3.2545e-01  1.8035e+00  1.0045e+00\n",
      "  5.8484e-01 -6.2031e-01 -4.3296e-01  2.3562e-01  1.3027e+00 -8.1264e-01\n",
      "  2.3158e+00  1.1030e+00 -6.0608e-01  1.0101e+00 -2.2426e-01  1.8908e-02\n",
      " -1.0931e-01  3.8350e-01  7.7362e-01 -8.1927e-02 -3.4040e-01 -1.5143e-03\n",
      " -5.6640e-02  8.7359e-01  1.4805e+00  6.9421e-01 -3.0966e-01 -9.0826e-01\n",
      "  3.7277e-03  8.4550e-01]\n",
      "Shape :  (50,)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_index[\"eat\"])\n",
    "print(\"Shape : \", embeddings_index[\"eat\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-4. Converting Sentences Into Vectors (Embedding Layer Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_output(X):\n",
    "    maxLen = 10\n",
    "    emb_dim = 50\n",
    "    embedding_out = np.zeros((X.shape[0], maxLen, emb_dim))\n",
    "    \n",
    "    for ix in range(X.shape[0]):\n",
    "        X[ix] = X[ix].split()\n",
    "        for ij in range(len(X[ix])):\n",
    "            # Go To Every Word In The Current (ix) Sentence\n",
    "            try:\n",
    "                embedding_out[ix][ij] = embeddings_index[X[ix][ij].lower()]\n",
    "            except:\n",
    "                embedding_out[ix][ij] = np.zeros((50,))\n",
    "    \n",
    "    return embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_train = embedding_output(X_train)\n",
    "embedding_matrix_test = embedding_output(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['never', 'talk', 'to', 'me', 'again']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(len(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 10, 50)\n",
      "(56, 10, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix_train.shape)\n",
    "print(embedding_matrix_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 5) (56, 5)\n",
      "[0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes=5)\n",
    "Y_test = to_categorical(Y_test, num_classes=5)\n",
    "print(Y_train.shape, Y_test.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-5. Define The RNN/LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 29,765\n",
      "Trainable params: 29,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(10,50))) # 10 Words In Each Sentence With Each Word Being A 50 Dimension Vector\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/100\n",
      "105/105 [==============================] - 1s 10ms/step - loss: 1.5949 - accuracy: 0.3143 - val_loss: 1.5764 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.57644, saving model to Best_LSTM_Model.h5\n",
      "Epoch 2/100\n",
      "105/105 [==============================] - 0s 366us/step - loss: 1.5592 - accuracy: 0.2952 - val_loss: 1.5877 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.57644\n",
      "Epoch 3/100\n",
      "105/105 [==============================] - 0s 378us/step - loss: 1.5253 - accuracy: 0.3333 - val_loss: 1.6027 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 1.57644\n",
      "Epoch 4/100\n",
      "105/105 [==============================] - 0s 375us/step - loss: 1.5207 - accuracy: 0.2952 - val_loss: 1.6152 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 1.57644\n",
      "Epoch 5/100\n",
      "105/105 [==============================] - 0s 371us/step - loss: 1.4788 - accuracy: 0.3048 - val_loss: 1.6298 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 1.57644\n",
      "Epoch 6/100\n",
      "105/105 [==============================] - ETA: 0s - loss: 1.4652 - accuracy: 0.34 - 0s 399us/step - loss: 1.4713 - accuracy: 0.3333 - val_loss: 1.6401 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 1.57644\n",
      "Epoch 7/100\n",
      "105/105 [==============================] - 0s 380us/step - loss: 1.4308 - accuracy: 0.3429 - val_loss: 1.6463 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 1.57644\n",
      "Epoch 8/100\n",
      "105/105 [==============================] - 0s 365us/step - loss: 1.4473 - accuracy: 0.3238 - val_loss: 1.6438 - val_accuracy: 0.2593\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.57644\n",
      "Epoch 9/100\n",
      "105/105 [==============================] - 0s 359us/step - loss: 1.4265 - accuracy: 0.3619 - val_loss: 1.6346 - val_accuracy: 0.2593\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.57644\n",
      "Epoch 10/100\n",
      "105/105 [==============================] - 0s 371us/step - loss: 1.4152 - accuracy: 0.3810 - val_loss: 1.6166 - val_accuracy: 0.2593\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.57644\n",
      "Epoch 11/100\n",
      "105/105 [==============================] - 0s 361us/step - loss: 1.3925 - accuracy: 0.4000 - val_loss: 1.5905 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.57644\n",
      "Epoch 12/100\n",
      "105/105 [==============================] - 0s 374us/step - loss: 1.3471 - accuracy: 0.4190 - val_loss: 1.5620 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.57644 to 1.56205, saving model to Best_LSTM_Model.h5\n",
      "Epoch 13/100\n",
      "105/105 [==============================] - 0s 351us/step - loss: 1.3147 - accuracy: 0.5238 - val_loss: 1.5340 - val_accuracy: 0.2222\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.56205 to 1.53403, saving model to Best_LSTM_Model.h5\n",
      "Epoch 14/100\n",
      "105/105 [==============================] - 0s 424us/step - loss: 1.2856 - accuracy: 0.4667 - val_loss: 1.5009 - val_accuracy: 0.2593\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.53403 to 1.50088, saving model to Best_LSTM_Model.h5\n",
      "Epoch 15/100\n",
      "105/105 [==============================] - 0s 551us/step - loss: 1.2824 - accuracy: 0.5524 - val_loss: 1.4654 - val_accuracy: 0.2593\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.50088 to 1.46542, saving model to Best_LSTM_Model.h5\n",
      "Epoch 16/100\n",
      "105/105 [==============================] - 0s 543us/step - loss: 1.2651 - accuracy: 0.5429 - val_loss: 1.4194 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.46542 to 1.41937, saving model to Best_LSTM_Model.h5\n",
      "Epoch 17/100\n",
      "105/105 [==============================] - 0s 559us/step - loss: 1.2207 - accuracy: 0.5238 - val_loss: 1.3733 - val_accuracy: 0.4074\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.41937 to 1.37329, saving model to Best_LSTM_Model.h5\n",
      "Epoch 18/100\n",
      "105/105 [==============================] - 0s 552us/step - loss: 1.2127 - accuracy: 0.5810 - val_loss: 1.3272 - val_accuracy: 0.4444\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.37329 to 1.32723, saving model to Best_LSTM_Model.h5\n",
      "Epoch 19/100\n",
      "105/105 [==============================] - 0s 542us/step - loss: 1.1284 - accuracy: 0.6381 - val_loss: 1.2982 - val_accuracy: 0.5185\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.32723 to 1.29824, saving model to Best_LSTM_Model.h5\n",
      "Epoch 20/100\n",
      "105/105 [==============================] - 0s 509us/step - loss: 1.1204 - accuracy: 0.5619 - val_loss: 1.2740 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.29824 to 1.27400, saving model to Best_LSTM_Model.h5\n",
      "Epoch 21/100\n",
      "105/105 [==============================] - 0s 558us/step - loss: 1.0491 - accuracy: 0.6476 - val_loss: 1.2511 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.27400 to 1.25112, saving model to Best_LSTM_Model.h5\n",
      "Epoch 22/100\n",
      "105/105 [==============================] - 0s 554us/step - loss: 0.9972 - accuracy: 0.6667 - val_loss: 1.2226 - val_accuracy: 0.5556\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.25112 to 1.22255, saving model to Best_LSTM_Model.h5\n",
      "Epoch 23/100\n",
      "105/105 [==============================] - 0s 572us/step - loss: 0.9353 - accuracy: 0.7143 - val_loss: 1.1681 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.22255 to 1.16812, saving model to Best_LSTM_Model.h5\n",
      "Epoch 24/100\n",
      "105/105 [==============================] - 0s 552us/step - loss: 0.9328 - accuracy: 0.6857 - val_loss: 1.1135 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.16812 to 1.11346, saving model to Best_LSTM_Model.h5\n",
      "Epoch 25/100\n",
      "105/105 [==============================] - 0s 572us/step - loss: 0.8712 - accuracy: 0.7524 - val_loss: 1.0695 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.11346 to 1.06947, saving model to Best_LSTM_Model.h5\n",
      "Epoch 26/100\n",
      "105/105 [==============================] - 0s 558us/step - loss: 0.7985 - accuracy: 0.7524 - val_loss: 1.0527 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.06947 to 1.05268, saving model to Best_LSTM_Model.h5\n",
      "Epoch 27/100\n",
      "105/105 [==============================] - 0s 503us/step - loss: 0.7461 - accuracy: 0.7429 - val_loss: 1.0288 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.05268 to 1.02882, saving model to Best_LSTM_Model.h5\n",
      "Epoch 28/100\n",
      "105/105 [==============================] - 0s 560us/step - loss: 0.7221 - accuracy: 0.7619 - val_loss: 1.0048 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.02882 to 1.00479, saving model to Best_LSTM_Model.h5\n",
      "Epoch 29/100\n",
      "105/105 [==============================] - 0s 541us/step - loss: 0.6956 - accuracy: 0.7619 - val_loss: 0.9955 - val_accuracy: 0.7037\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.00479 to 0.99548, saving model to Best_LSTM_Model.h5\n",
      "Epoch 30/100\n",
      "105/105 [==============================] - 0s 506us/step - loss: 0.6377 - accuracy: 0.8286 - val_loss: 1.0116 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.99548\n",
      "Epoch 31/100\n",
      "105/105 [==============================] - 0s 503us/step - loss: 0.6163 - accuracy: 0.7905 - val_loss: 1.0299 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.99548\n",
      "Epoch 32/100\n",
      "105/105 [==============================] - 0s 503us/step - loss: 0.5549 - accuracy: 0.8571 - val_loss: 1.0072 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.99548\n",
      "Epoch 33/100\n",
      "105/105 [==============================] - 0s 536us/step - loss: 0.5263 - accuracy: 0.8286 - val_loss: 1.0105 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.99548\n",
      "Epoch 34/100\n",
      "105/105 [==============================] - 0s 487us/step - loss: 0.5338 - accuracy: 0.8476 - val_loss: 1.0171 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.99548\n",
      "Epoch 35/100\n",
      "105/105 [==============================] - 0s 483us/step - loss: 0.4741 - accuracy: 0.8381 - val_loss: 1.0116 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.99548\n",
      "Epoch 36/100\n",
      "105/105 [==============================] - 0s 522us/step - loss: 0.4587 - accuracy: 0.8762 - val_loss: 1.0017 - val_accuracy: 0.5926\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.99548\n",
      "Epoch 37/100\n",
      "105/105 [==============================] - 0s 493us/step - loss: 0.4471 - accuracy: 0.8286 - val_loss: 0.9964 - val_accuracy: 0.6296\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.99548\n"
     ]
    }
   ],
   "source": [
    "earlystop = EarlyStopping(monitor=\"val_accuracy\", patience=10)\n",
    "checkpoint = ModelCheckpoint(\"Best_LSTM_Model.h5\", monitor='val_loss', verbose=True, save_best_only=True)\n",
    "hist = model.fit(embedding_matrix_train, Y_train, epochs=100, batch_size=64, shuffle=True, validation_split=0.2, callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading The Best Model\n",
    "model.load_weights(\"Best_LSTM_Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 2 2 2 3 2 4 2 1 2 2 3 1 3 3 2 3 4 0 0 4 2 3 3 1 0 1 2 2 1 2 3 0 2 2\n",
      " 0 4 0 1 0 2 1 2 0 3 2 3 1 1 0 3 2 2 3]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_classes(embedding_matrix_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 210us/step\n",
      "Testing Accuracy :  71.43 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Accuracy : \", round(100 * model.evaluate(embedding_matrix_test, Y_test)[1], 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " I want to eat\n",
      "Actual :  üç¥\n",
      "Prediction :  üç¥\n",
      "\n",
      " he did not answer\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " he got a very nice raise\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " she got me a nice present\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " ha ha ha it was so funny\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " he is a good friend\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " I am upset\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " We had such a lovely dinner tonight\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " where is the food\n",
      "Actual :  üç¥\n",
      "Prediction :  üç¥\n",
      "\n",
      " Stop making this joke ha ha ha\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " where is the ball\n",
      "Actual :  ‚öæ\n",
      "Prediction :  ‚öæ\n",
      "\n",
      " work is hard\n",
      "Actual :  üòû\n",
      "Prediction :  üòÉ\n",
      "\n",
      " This girl is messing with me\n",
      "Actual :  üòû\n",
      "Prediction :  üòÉ\n",
      "\n",
      " are you serious\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " Let us go play baseball\n",
      "Actual :  ‚öæ\n",
      "Prediction :  ‚öæ\n",
      "\n",
      " This stupid grader is not working\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " work is horrible\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " Congratulation for having a baby\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n",
      "\n",
      " stop pissing me off\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " any suggestions for dinner\n",
      "Actual :  üç¥\n",
      "Prediction :  üç¥\n",
      "\n",
      " I love taking breaks\n",
      "Actual :  ‚ù§Ô∏è\n",
      "Prediction :  ‚ù§Ô∏è\n",
      "\n",
      " you brighten my day\n",
      "Actual :  üòÉ\n",
      "Prediction :  ‚ù§Ô∏è\n",
      "\n",
      " I boiled rice\n",
      "Actual :  üç¥\n",
      "Prediction :  üç¥\n",
      "\n",
      " she is a bully\n",
      "Actual :  üòû\n",
      "Prediction :  üòÉ\n",
      "\n",
      " Why are you feeling bad\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " I am upset\n",
      "Actual :  üòû\n",
      "Prediction :  üòû\n",
      "\n",
      " give me the ball\n",
      "Actual :  ‚öæ\n",
      "Prediction :  ‚öæ\n",
      "\n",
      " My grandmother is the love of my life\n",
      "Actual :  ‚ù§Ô∏è\n",
      "Prediction :  ‚ù§Ô∏è\n",
      "\n",
      " enjoy your game\n",
      "Actual :  ‚öæ\n",
      "Prediction :  ‚öæ\n",
      "\n",
      " valentine day is near\n",
      "Actual :  üòÉ\n",
      "Prediction :  üòÉ\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"\\n\", \" \".join(X_test[i]))\n",
    "    print(\"Actual : \",emoji.emojize(emoji_dictionary[str(np.argmax(Y_test[i]))]))\n",
    "    print(\"Prediction : \",emoji.emojize(emoji_dictionary[str(pred[i])]))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
